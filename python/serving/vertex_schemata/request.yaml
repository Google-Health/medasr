# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

title: MedASRRequest
type: object
description: >
  The schema for a single Speech-to-Text transcription request. Parameters are aligned
  with the core functionality of the OpenAI Transcription API:
  https://platform.openai.com/docs/api-reference/audio/createTranscription
additionalProperties: false
required:
  - file
properties:
  file:
    type: string
    format: binary
    description: >
      The audio file object (not file name) to transcribe, in one of these formats: flac,
      mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
    title: Audio File
  model:
    anyOf:
      - type: string
      - type: "null"
    description: >
      This field is included for compatibility with the OpenAI Transcription API. It is not
      currently used, because the model is implicitly selected based on the endpoint used.
    title: Model
  chunking_strategy:
    anyOf:
      - type: string
        enum:
          - auto
      - $ref: "#/components/schemas/ServerVAD"
      - type: "null"
    description: >
      Controls how the audio is cut into chunks. When set to "auto", the server
      first normalizes loudness and then uses voice activity detection (VAD) to
      choose boundaries. A server_vad object can be provided to tweak VAD detection
      parameters manually. If unset, the audio is transcribed as a single block.
    title: Chunking Strategy
  include:
    anyOf:
      - type: array
        items:
          type: string
          enum:
            - logprobs
      - type: "null"
    description: >
      Additional information to include in the transcription response. logprobs will
      return the log probabilities of the tokens in the response to understand the
      model's confidence in the transcription.
    title: Include
  language:
    anyOf:
      - type: string
      - type: "null"
    description: >
      The language of the input audio. Supplying the input language in ISO-639-1
      (e.g. en) format will improve accuracy and latency.
    title: Language
  prompt:
    anyOf:
      - type: string
      - type: "null"
    description: >
      An optional text to guide the model's style or continue a previous audio
      segment. The prompt should match the audio language.
    title: Prompt
  temperature:
    anyOf:
      - type: number
        minimum: 0
        maximum: 1
      - type: "null"
    default: 0
    description: >
      The sampling temperature, between 0 and 1. Higher values like 0.8 will make
      the output more random, while lower values like 0.2 will make it more
      focused and deterministic.
    title: Temperature

components:
  schemas:
    ServerVAD:
      title: ServerVAD
      type: object
      description: >
        Object to tweak Voice Activity Detection (VAD) parameters manually.
      additionalProperties: false
      required:
        - type
      properties:
        type:
          type: string
          description: >
            Must be set to 'server_vad' to enable manual chunking using server side VAD.
          enum:
            - server_vad
        prefix_padding_ms:
          type: integer
          description: Amount of audio to include before the VAD detected speech (in milliseconds).
          default: 300
        silence_duration_ms:
          type: integer
          description: >
            Duration of silence to detect speech stop (in milliseconds). With shorter values the
            model will respond more quickly, but may jump in on short pauses from the user.
          default: 200
        threshold:
          type: number
          description: >
            Sensitivity threshold (0.0 to 1.0) for voice activity detection. A higher
            threshold will require louder audio to activate the model, and thus might perform
            better in noisy environments.
          default: 0.5
          minimum: 0.0
          maximum: 1.0