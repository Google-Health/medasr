{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYba2hfAs0AS"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kILpWz4Gs5Kh"
      },
      "source": [
        "# Quick start with Model Garden - MedASR\n",
        "\n",
        "<table><tbody><tr>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogle-Health%2Fmedasr%2Fmain%2Fnotebooks%2Fquick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/google-health/medasr/blob/main/notebooks/quick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"GitHub logo\" src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" width=\"32px\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRGljGF2lUWd"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use MedASR in Vertex AI to transcribe medical audio to text using online inference.\n",
        "\n",
        "**Online inferences** are synchronous requests that are made to the endpoint deployed from Model Garden and are served with low latency. Online inferences are useful if the model outputs are being used in production. The cost for online inference is based on the time a virtual machine spends waiting in an active state (an endpoint with a deployed model) to handle inference requests.\n",
        "\n",
        "Vertex AI makes it easy to serve your model and make it accessible to the world. Learn more about [Vertex AI](https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform).\n",
        "\n",
        "### Objectives\n",
        "\n",
        "- Deploy MedASR to a Vertex AI Endpoint and get online inferences.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emPr6M1fs5Kj"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag_zmUlgmJD8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies and import packages\n",
        "\n",
        "! pip install -qU --upgrade pip\n",
        "! pip install -qU 'google-cloud-aiplatform>=1.101.0' jiwer levenshtein\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "models, endpoints = {}, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zMsN9Ep1mJD8"
      },
      "outputs": [],
      "source": [
        "# @title Set up Google Cloud environment\n",
        "\n",
        "# @markdown #### Prerequisites\n",
        "\n",
        "# @markdown 1. Make sure that [billing is enabled](https://cloud.google.com/billing/docs/how-to/modify-project) for your project.\n",
        "\n",
        "# @markdown 2. Make sure that either the Compute Engine API is enabled or that you have the [Service Usage Admin](https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin) (`roles/serviceusage.serviceUsageAdmin`) role to enable the API.\n",
        "\n",
        "# @markdown This section sets the default Google Cloud project and region, enables the Compute Engine API (if not already enabled), and initializes the Vertex AI API.\n",
        "\n",
        "# Get the default project ID.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# Enable the Compute Engine API, if not already.\n",
        "print(\"Enabling Compute Engine API.\")\n",
        "! gcloud services enable compute.googleapis.com\n",
        "\n",
        "# Initialize Vertex AI API.\n",
        "print(\"Initializing Vertex AI API.\")\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Retrieve sample data\n",
        "\n",
        "# @markdown This notebook uses a sample medical audio file and transcript.\n",
        "\n",
        "! gcloud storage cp gs://healthai-us/medasr/test_audio.wav test_audio.wav\n",
        "with open(\"test_audio.wav\", \"rb\") as f:\n",
        "    audio_bytes = f.read()\n",
        "sample_transcript = \"Exam type CT chest PE protocol period. Indication 54 year old female, shortness of breath, evaluate for PE period. Technique standard protocol period. Findings colon. Pulmonary vasculature colon. The main PA is patent period. There are filling defects in the segmental branches of the right lower lobe comma compatible with acute PE period. No saddle embolus period. Lungs colon. No pneumothorax period. Small bilateral effusions comma right greater than left period. New paragraph. Impression colon. Acute segmental PE right lower lobe period.\"\n",
        "display(Audio(audio_bytes, autoplay=False))"
      ],
      "metadata": {
        "id": "4GJMn-QvZ4up",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define utility functions\n",
        "\n",
        "# @markdown These functions will be used to evaluate the word error rate (WER) of the generated transcripts.\n",
        "\n",
        "import re\n",
        "import jiwer\n",
        "import Levenshtein\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "  s = s.lower()\n",
        "  s = re.sub(r\"[^ a-z0-9']\", ' ', s)\n",
        "  s = ' '.join(s.split())\n",
        "  return s\n",
        "\n",
        "def _colored(text, color):\n",
        "    if color == 'red':\n",
        "        return f\"\\033[91m{text}\\033[0m\"\n",
        "    elif color == 'green':\n",
        "        return f\"\\033[92m{text}\\033[0m\"\n",
        "    return text\n",
        "\n",
        "def evaluate(\n",
        "    ref_text: str,\n",
        "    hyp_text: str,\n",
        "    delete_color: str = 'red',\n",
        "    insert_color: str = 'green',\n",
        ") -> None:\n",
        "  print('HYP:', hyp_text)\n",
        "  normalized_ref = normalize(ref_text)\n",
        "  normalized_hyp = normalize(hyp_text)\n",
        "\n",
        "  # Calculate word lists early so we can use them for both jiwer and diffs\n",
        "  ref_words = normalized_ref.split()\n",
        "  hyp_words = normalized_hyp.split()\n",
        "\n",
        "  # jiwer.process_words expects a list of strings (sentences) or list of list of words\n",
        "  measures = jiwer.process_words([normalized_ref], [normalized_hyp])\n",
        "\n",
        "  # Calculate edit operations using Levenshtein for the colored diff\n",
        "  edits = Levenshtein.editops(ref_words, hyp_words)\n",
        "\n",
        "  r = 0 # Index for the reference words for diff building\n",
        "  diff = ''\n",
        "\n",
        "  for op, i, j in edits:\n",
        "    # Add matched words before the current edit\n",
        "    if r < i:\n",
        "      diff += ' ' + ' '.join(ref_words[r:i])\n",
        "    r = i # Update reference index for next iteration\n",
        "\n",
        "    if op == 'replace':\n",
        "      diff += (\n",
        "          f' {_colored(f\"{{-{ref_words[i]}-}}\", delete_color)}'\n",
        "          f' {_colored(f\"{{+{hyp_words[j]}+}}\", insert_color)}'\n",
        "      )\n",
        "      r += 1 # Advance reference index after replacement\n",
        "    elif op == 'insert':\n",
        "      diff += f' {_colored(f\"{{+{hyp_words[j]}+}}\", insert_color)}'\n",
        "      # Reference index `r` does not advance for an insertion\n",
        "    elif op == 'delete':\n",
        "      diff += f' {_colored(f\"{{-{ref_words[i]}-}}\", delete_color)}'\n",
        "      r += 1 # Advance reference index after deletion\n",
        "\n",
        "  # Add any remaining matched words from the reference\n",
        "  if r < len(ref_words):\n",
        "    diff += ' ' + ' '.join(ref_words[r:])\n",
        "\n",
        "  print(\n",
        "      f'WER: {measures.wer * 100:.2f}%: '\n",
        "      f'insertions {measures.insertions}, deletions {measures.deletions}, substitutions {measures.substitutions}, '\n",
        "      f'ref tokens {len(ref_words)}'\n",
        "  )\n",
        "  print(diff)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1bz6RCO2c7h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bak-klNTmJD8"
      },
      "source": [
        "## Get online inferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjOWCeGJu-94",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import deployed model\n",
        "\n",
        "# @markdown To get [online inferences](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions), you will need a MedASR [Vertex AI Endpoint](https://cloud.google.com/vertex-ai/docs/general/deployment) that has been deployed from Model Garden. If you have not already done so, go to the [MedASR model card](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/medasr) and click \"Deploy model\" to deploy the model.\n",
        "\n",
        "# @markdown Note: Endpoints deployed from Model Garden must be [dedicated endpoints](https://cloud.google.com/vertex-ai/docs/predictions/choose-endpoint-type).\n",
        "\n",
        "# @markdown This section gets the Vertex AI Endpoint resource that you deployed from Model Garden to use for online inferences.\n",
        "\n",
        "# @markdown Fill in the endpoint ID and region below. You can find your deployed endpoint on the [Vertex AI Endpoints page](https://console.cloud.google.com/vertex-ai/online-prediction/endpoints).\n",
        "\n",
        "ENDPOINT_ID = \"\"  # @param {type: \"string\", placeholder:\"e.g. 123456789\"}\n",
        "ENDPOINT_REGION = \"\"  # @param {type: \"string\", placeholder:\"e.g. us-central1\"}\n",
        "\n",
        "endpoints[\"endpoint\"] = aiplatform.Endpoint(\n",
        "    endpoint_name=ENDPOINT_ID,\n",
        "    project=PROJECT_ID,\n",
        "    location=ENDPOINT_REGION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhijNE6PnWn7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run inference using the Vertex AI SDK\n",
        "\n",
        "# @markdown This section shows how to send [online prediction](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions) requests to your Vertex AI endpoint.\n",
        "\n",
        "# @markdown Click \"Show code\" to see more details.\n",
        "\n",
        "request = {\n",
        "    \"file\": base64.b64encode(audio_bytes).decode(\"utf-8\"),\n",
        "}\n",
        "\n",
        "response = endpoints[\"endpoint\"].raw_predict(\n",
        "    body=json.dumps(request).encode(\"utf-8\"),\n",
        "    headers={\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    },\n",
        ")\n",
        "generated_transcript = json.loads(response.content)[\"text\"]\n",
        "\n",
        "print(generated_transcript)\n",
        "evaluate(sample_transcript, generated_transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yfFlkncxzDF"
      },
      "source": [
        "\n",
        "## Next steps\n",
        "\n",
        "Explore the other [notebooks](https://github.com/google-health/medasr/blob/main/notebooks) to learn what else you can do with the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paQNyrzT_mX_"
      },
      "source": [
        "## Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edUIpvZZ_mYA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown  Delete the experiment models and endpoints to recycle the resources\n",
        "# @markdown  and avoid unnecessary continuous charges that may incur.\n",
        "\n",
        "# Undeploy model and delete endpoint.\n",
        "for endpoint in endpoints.values():\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "# Delete models.\n",
        "for model in models.values():\n",
        "    model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
